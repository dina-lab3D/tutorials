{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dina-lab3D/tutorials/blob/main/NanoNet/net.ipynb)\n",
        "\n",
        "#NanoNet \n",
        "\n",
        "NanoNet is a novel deep learning-based end-to-end modeling tool that given a sequence directly produces the 3D coordinates of the CÎ² atoms of the entire VH domain. It can be used in order to predict structures of nanobodies, VH regions of mAbs and VB regions of TCRs.\n",
        "\n",
        "**NanoNet architecture**:\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "<img src=https://drive.google.com/uc?id=1DdACpv5loaOnKbrIIlJSygUUmt9dRUut width=\"2000\">\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OeLrSY7MkKXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download modeller, first get license key from **[here](https://salilab.org/modeller/registration.html)** .\n",
        "from IPython.display import clear_output\n",
        "license_key = '' #@param {type:\"string\"}\n",
        "#MODELIRANJE\n",
        "!wget https://salilab.org/modeller/10.1/modeller-10.1.tar.gz\n",
        "!tar -zxf modeller-10.1.tar.gz\n",
        "!echo \"MODELLER extraction completed\"\n",
        "%cd modeller-10.1\n",
        "#And we prepare a file containing the minimal setup elements\n",
        "#For installing, including a license key\n",
        "with open('modeller_config', 'a') as f:\n",
        "  f.write(\"3\\n\")\n",
        "  f.write(\"/content/compiled/MODELLER\\n\")\n",
        "#ADD YOUR LICENSE KEY HERE!\n",
        "  f.write(f\"{license_key}\\n\")\n",
        "!./Install < modeller_config\n",
        "!echo \"MODELLER set up completed\"\n",
        "\n",
        "%cd /content/\n",
        "#Creating a symbolic link\n",
        "%cd modeller-10.1\n",
        "!ln -sf /content/compiled/MODELLER/bin/mod10.1 /usr/bin/\n",
        "%cd /content/\n",
        "#Checking if MODELLER works\n",
        "!mod10.1 | awk 'NR==1{if($1==\"usage:\") print \"MODELLER succesfully installed\"; else if($1!=\"usage:\") print \"Something went wrong. Please install again\"}'\n",
        "\n",
        "with open(\"/content/compiled/MODELLER/modlib/modeller/config.py\", \"r\") as file:\n",
        "  lines = file.readlines()\n",
        "\n",
        "with open(\"/content/compiled/MODELLER/modlib/modeller/config.py\", \"w\") as file:\n",
        "  file.write(lines[0])\n",
        "  file.write(f\"license = '{license_key}'\\n\")\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MM3UHILzdcjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing packages and get the relevent files"
      ],
      "metadata": {
        "id": "fClhWfmeLKMh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k0q29Z3ukKI"
      },
      "source": [
        "\n",
        "!pip install Bio\n",
        "!pip install import-ipynb\n",
        "!pip install py3Dmol\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dina-lab3D/tutorials/main/NanoNet/6zrv.pdb \n",
        "!wget https://raw.githubusercontent.com/dina-lab3D/tutorials/main/NanoNet/modeller_side_chains.py \n",
        "!wget https://github.com/dina-lab3D/tutorials/raw/main/NanoNet/train_input.npy.zip \n",
        "!wget https://github.com/dina-lab3D/tutorials/raw/main/NanoNet/train_labels.npy.zip\n",
        "!wget https://raw.githubusercontent.com/dina-lab3D/tutorials/main/NanoNet/utils.ipynb \n",
        "!wget https://raw.githubusercontent.com/dina-lab3D/tutorials/main/NanoNet/align.py\n",
        "\n",
        "!git clone https://github.com/dina-lab3D/NanoNet --quiet\n",
        "\n",
        "!unzip train_input.npy.zip\n",
        "!unzip train_labels.npy.zip\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCeXnsvlLtE-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import py3Dmol\n",
        "import import_ipynb\n",
        "import utils\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the hyper parameters for the convolutional neural network"
      ],
      "metadata": {
        "id": "gamCsPCbLYEo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y4fRqWLLwhR",
        "cellView": "form"
      },
      "source": [
        "###############################################################################\n",
        "#                                                                             #\n",
        "#                        Network Hyper-Parameters                             #\n",
        "#                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### number of ResNet blocks for the first ResNet and the kernel size.\n",
        "\n",
        "RESNET_1_BLOCKS = 3 #@param [1, 2, 3,4, 5] {type:\"raw\"}\n",
        "RESNET_1_KERNEL_SIZE = 15 #@param [7, 15, 25] {type:\"raw\"}\n",
        "RESNET_1_KERNEL_NUM = 64 #@param [32, 64, 128] {type:\"raw\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### number of ResNet blocks for the second ResNet, dilation list to repeat and the kernel size.\n",
        "\n",
        "RESNET_2_BLOCKS = 1  #@param [1, 3, 5] {type:\"raw\"}\n",
        "RESNET_2_KERNEL_SIZE = 5 #@param [3, 5, 7] {type:\"raw\"}\n",
        "RESNET_2_KERNEL_NUM = 140 #@param [70, 140] {type:\"raw\"}\n",
        "DILATION = [1,2,4,8,16] \n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### percentage of dropout for the dropout layer\n",
        "DROPOUT = 0.25 #@param [0.0, 0.1, 0.25, 0.5] {type:\"raw\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### number of epochs, Learning rate and Batch size\n",
        "EPOCHS = 100 #@param [50, 100, 125] {type:\"raw\"}\n",
        "LR = 0.001 #@param [0.0001, 0.001, 0.01] {type:\"raw\"}\n",
        "BATCH = 16 #@param [16, 32, 64, 128] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a ResNet layer"
      ],
      "metadata": {
        "id": "AYqe8-fNLl44"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7wc4YJMo5V-"
      },
      "source": [
        "def resnet_1(input_layer): \n",
        "    \"\"\"\n",
        "    ResNet layer - input -> BatchNormalization -> Relu -> Conv1D -> BatchNormalization -> Relu -> Conv1D -> Add\n",
        "    :param input_layer: input layer for the ResNet\n",
        "    :return: last layer of the ResNet\n",
        "    \"\"\"\n",
        "    for i in range(RESNET_1_BLOCKS):\n",
        "\n",
        "        batch_layer = layers.BatchNormalization()(input_layer)\n",
        "        conv1d_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same')(batch_layer)\n",
        "        relu_layer = layers.Activation('relu')(conv1d_layer)\n",
        "\n",
        "        batch_layer = layers.BatchNormalization()(relu_layer)\n",
        "        conv1d_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same')(batch_layer)\n",
        "        relu_layer = layers.Activation('relu')(conv1d_layer)\n",
        "\n",
        "        input_layer = layers.Add()([relu_layer, input_layer])\n",
        "\n",
        "    return input_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a Dilated ResNet layer\n"
      ],
      "metadata": {
        "id": "XpXNhw2HLsPQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXj05_d7o5io"
      },
      "source": [
        "def resnet_2(input_layer):  # TODO: implement this!\n",
        "    \"\"\"\n",
        "    Dilated ResNet layer - input -> BatchNormalization -> Relu -> dilated Conv1D -> BatchNormalization -> Relu -> dilated Conv1D -> Add\n",
        "    :param input_layer: input layer for the ResNet\n",
        "    :return: last layer of the ResNet\n",
        "    \"\"\"\n",
        "    for i in range(RESNET_2_BLOCKS):\n",
        "        for d in DILATION:\n",
        "\n",
        "            batch_layer = layers.BatchNormalization()(input_layer)\n",
        "            conv1d_layer = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding='same', dilation_rate=d)(batch_layer)\n",
        "            relu_layer = layers.Activation('relu')(conv1d_layer)\n",
        "\n",
        "            batch_layer = layers.BatchNormalization()(relu_layer)\n",
        "            conv1d_layer = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding='same', dilation_rate=d)(batch_layer)\n",
        "            relu_layer = layers.Activation('relu')(conv1d_layer)\n",
        "\n",
        "            input_layer = layers.Add()([relu_layer, input_layer])\n",
        "\n",
        "\n",
        "    return input_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the entire neural network architecture "
      ],
      "metadata": {
        "id": "wrW5g8WcLzVQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_CN7eEopE3A"
      },
      "source": [
        "def build_network():\n",
        "    \"\"\"\n",
        "    builds the neural network architecture as shown in the exercise.\n",
        "    :return: Keras Model\n",
        "    \"\"\"\n",
        "    # input, shape (NB_MAX_LENGTH,FEATURE_NUM)\n",
        "    input_layer = tf.keras.Input(shape=(utils.NB_MAX_LENGTH, utils.FEATURE_NUM))\n",
        "\n",
        "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
        "    conv1d_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same')(input_layer)\n",
        "\n",
        "    # first ResNet -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
        "    resnet_layer = resnet_1(conv1d_layer)\n",
        "\n",
        "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    conv1d_layer = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding=\"same\")(resnet_layer)\n",
        "\n",
        "    # second ResNet -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    resnet_layer = resnet_2(conv1d_layer)\n",
        "\n",
        "    # dropout -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    dropout_layer = layers.Dropout(DROPOUT)(resnet_layer)\n",
        "\n",
        "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    conv1d_layer = layers.Conv1D(RESNET_2_KERNEL_NUM // 2, RESNET_2_KERNEL_SIZE, padding=\"same\", activation=\"elu\")(dropout_layer)\n",
        "\n",
        "    # Dense -> shape = (NB_MAX_LENGTH, OUTPUT_SIZE)\n",
        "    # outpur_layer = layers.Conv1D(utils.OUTPUT_SIZE, RESNET_2_KERNEL_SIZE, padding=\"same\")(conv1d_layer)\n",
        "\n",
        "    outpur_layer = layers.Dense(utils.OUTPUT_SIZE)(conv1d_layer)\n",
        "\n",
        "    return tf.keras.Model(input_layer, outpur_layer, name=\"my_network\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fucntion for ploting the training and validation losses"
      ],
      "metadata": {
        "id": "jhje_aC0MBur"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8itDQ59HpFlL"
      },
      "source": [
        "def plot_val_train_loss(history):\n",
        "    \"\"\"\n",
        "    plots the train and validation loss of the model at each epoch, saves it in 'model_loss_history.png'\n",
        "    :param history: history object (output of fit function)\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    ig, axes = plt.subplots(1, 1, figsize=(15,3))\n",
        "    axes.plot(history.history['loss'], label='Training loss')\n",
        "    axes.plot(history.history['val_loss'], label='Validation loss')\n",
        "    axes.legend()\n",
        "    axes.set_title(\"Train and Val MSE loss\")\n",
        "\n",
        "    plt.savefig(\"model_loss_history\") \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the training dataset and split it to training and validation sets\n",
        "\n",
        "\n",
        "X - the input for the network, Nb sequence (as one-hot representation):\n",
        "\n",
        "original sequence - VGG...Q\n",
        "one-hot representation:\n",
        "\n",
        "<br>\n",
        "<img src=https://drive.google.com/uc?id=1jWfEkFvs6JSNdpvaH8ZEbdDnOD1xCSTn width=\"300\">\n",
        "\n",
        "\n",
        "Y - the output of the network, backbone + CB coordinates of the solved structure (after alignment to a reference nanobody)\n",
        "\n",
        "\n",
        "<br>\n",
        "<img src=https://drive.google.com/uc?id=1ui5n-o6xxCV13zd6tKFEXPW2eradH95M width=\"300\"> <img src=https://drive.google.com/uc?id=1SdiqFwJEgvUAMPc8GV51dI25_A_iSxJP width=\"400\"> \n"
      ],
      "metadata": {
        "id": "ntwyZahfMGhY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQLxqy33pJk2"
      },
      "source": [
        "\n",
        "model = build_network()\n",
        "\n",
        "\n",
        "# you can load here your input and output data\n",
        "\n",
        "# X = numpy array of shape (2141,NB_MAX_LENGTH,FEATURE_NUM) of all the data input.\n",
        "# Y = numpy array of shape (2141,NB_MAX_LENGTH,OUTPUT_SIZE) of all the data labels.\n",
        "\n",
        "X = np.load(\"train_input.npy\")\n",
        "Y = np.load(\"train_labels.npy\")\n",
        "\n",
        "# split into validation and test sets as you like\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1,  shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the loss function - Mean squared error (equivalent to RMSD) + CA distance loss\n",
        "\n",
        "<br>\n",
        "<img src=https://drive.google.com/uc?id=1YogRx01bTicTak8jzFDgzNxMPCnUdPVC width=\"380\">\n",
        "\n",
        "<br>\n",
        "<img src=https://drive.google.com/uc?id=1cfdTQ2nlvewzcehxp49d1aOz_q9ZU7Ge width=\"350\">\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J3udZhQ5XZKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ca_distance_loss(real, pred):\n",
        "    \"\"\"\n",
        "    masked flat-bottom l1 loss for antibody ca distances.\n",
        "    \"\"\"\n",
        "\n",
        "    mse_loss = tf.math.reduce_mean((real- pred)**2, axis=-1)\n",
        "    mse_loss = tf.math.reduce_mean(mse_loss, axis=-1)\n",
        "\n",
        "    mask = tf.cast(tf.math.logical_not(tf.math.reduce_all(tf.math.equal(real, 0), axis=-1)), dtype=real.dtype)\n",
        "    pred_ca = pred[:, :, 3:6]\n",
        "    rolled_pred_ca = tf.roll(pred_ca, shift=1, axis=-2)\n",
        "    ca_dist = tf.math.reduce_sum((pred_ca - rolled_pred_ca) ** 2, axis=-1)\n",
        "    ca_dist = (tf.math.sqrt(ca_dist) - 3.77) ** 2\n",
        "    ca_mask = tf.math.multiply(mask, tf.roll(mask, shift=1, axis=-1))\n",
        "    ca_dist *= ca_mask\n",
        "    ca_dist = (tf.reduce_sum(ca_dist, axis=-1) / tf.reduce_sum(ca_mask,axis=-1))\n",
        "\n",
        "    return mse_loss + ca_dist "
      ],
      "metadata": {
        "id": "fDLXT185XZiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set loss function + algorithm for optimization"
      ],
      "metadata": {
        "id": "Ae5cbwOvM0Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "model.compile(optimizer = optimizer, loss=[\"mse\", ca_distance_loss])\n",
        "save_callback = tf.keras.callbacks.ModelCheckpoint(\"my_model\",save_best_only=True, verbose=1)"
      ],
      "metadata": {
        "id": "pAH58VxPMpVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the neural network"
      ],
      "metadata": {
        "id": "Opau1jqnNDZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model (use EPOCH for epoch parameter and BATCH for batch_size parameter)\n",
        "net_history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=EPOCHS, verbose=1, batch_size=BATCH, callbacks=[save_callback])\n",
        "plot_val_train_loss(net_history)"
      ],
      "metadata": {
        "id": "-jaLI4HKNEBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict the structure of a new Nb (6zrv) using the trained neural network"
      ],
      "metadata": {
        "id": "GtsLDrP1NKb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.models.load_model(\"NanoNet/NanoNet\", compile=False)\n",
        "model = tf.keras.models.load_model(\"my_model\", compile=False)\n",
        "\n",
        "seq, aa = utils.get_seq_aa(\"6zrv.pdb\", \"H\")\n",
        "one_hot = utils.generate_input(\"6zrv.pdb\")\n",
        "\n",
        "predicted_xyz = model.predict(np.expand_dims(one_hot, axis=0))[0]\n",
        "utils.matrix_to_pdb(seq, predicted_xyz, \"6zrv_network\")\n",
        "\n",
        "with open(\"6zrv_network.pdb\") as ifile:\n",
        "    predicted = \"\".join([x for x in ifile])\n",
        "with open(\"6zrv.pdb\") as ifile:\n",
        "    true = \"\".join([x for x in ifile])\n",
        "\n",
        "r,g,b = 255,0,0\n",
        "print(f\"\\033[38;2;{r};{g};{b}mPredicted model \\033[38;2;255;255;255m\")\n",
        "r,g,b = 0,0,255\n",
        "print(f\"\\033[38;2;{r};{g};{b}mNative structure \\033[38;2;255;255;255m\")\n",
        "view = py3Dmol.view(width=500, height=500)\n",
        "view.addModelsAsFrames(predicted)\n",
        "view.setStyle({'model': 0}, {\"cartoon\": {'arrows':True, 'color': 'red'}})\n",
        "view.addModelsAsFrames(true)\n",
        "view.setStyle({'model': 1}, {\"cartoon\": {'arrows':True, 'color': 'blue'}})\n",
        "view.zoomTo()\n",
        "view.show()\n"
      ],
      "metadata": {
        "id": "YDwg_XRPNKy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for reconstructing side chains and relaxing the model (using modeller)"
      ],
      "metadata": {
        "id": "xJz2Q3Yfgi6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mod10.1 modeller_side_chains.py 6zrv_network.pdb $seq\n",
        "!mv pdb_seq.B99990001.pdb 6zrv_network_side_chains.pdb\n",
        "!python align.py 6zrv.pdb 6zrv_network_side_chains.pdb"
      ],
      "metadata": {
        "id": "hAAZrcdVif-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View relaxed structure with side chains"
      ],
      "metadata": {
        "id": "y-puJZQpjpRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"6zrv_network_side_chains_aligned.pdb\") as ifile:\n",
        "    predicted = \"\".join([x for x in ifile])\n",
        "with open(\"6zrv.pdb\") as ifile:\n",
        "    true = \"\".join([x for x in ifile])\n",
        "\n",
        "\n",
        "r,g,b = 255,0,0\n",
        "print(f\"\\033[38;2;{r};{g};{b}mPredicted model \\033[38;2;255;255;255m\")\n",
        "r,g,b = 0,0,255\n",
        "print(f\"\\033[38;2;{r};{g};{b}mNative structure \\033[38;2;255;255;255m\")\n",
        "view = py3Dmol.view(width=500, height=500)\n",
        "view.addModelsAsFrames(predicted)\n",
        "view.setStyle({'model': 0}, {\"cartoon\": {'arrows':True, 'color': 'red'}, 'stick':{'color': 'red'}})\n",
        "view.addModelsAsFrames(true)\n",
        "view.setStyle({'model': 1}, {\"cartoon\": {'arrows':True, 'color': 'blue'}, 'stick':{'color': 'blue'}})\n",
        "view.zoomTo()\n",
        "view.show()\n"
      ],
      "metadata": {
        "id": "AY5uR24bjojt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}